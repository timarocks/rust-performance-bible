name: Benchmark Suite

on:
  push:
    branches: [ main ]
    paths:
      - 'book/**'
      - '.github/workflows/benchmark.yml'
      - 'Cargo.toml'
      - 'Cargo.lock'
  pull_request:
    branches: [ main ]
    paths:
      - 'book/**'
      - '.github/workflows/benchmark.yml'
      - 'Cargo.toml'
      - 'Cargo.lock'
  workflow_dispatch:
    inputs:
      baseline:
        description: 'Baseline branch/tag to compare against'
        required: false
        default: 'main'

env:
  CARGO_TERM_COLOR: always
  RUSTFLAGS: "-C target-cpu=native"
  CARGO_INCREMENTAL: 0
  CARGO_NET_RETRY: 5
  RUST_BACKTRACE: full

jobs:
  benchmark:
    name: Run Benchmarks (${{ matrix.os }}, ${{ matrix.rust }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        rust: [stable, nightly]
        include:
          - os: ubuntu-latest
            cache-key: ubuntu-latest
          - os: macos-latest
            cache-key: macos-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for comparisons
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@master
      with:
        toolchain: ${{ matrix.rust }}
        components: rustfmt, clippy
    
    - name: Cache cargo registry and index
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: ${{ matrix.cache-key }}-${{ matrix.rust }}-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: |
          ${{ matrix.cache-key }}-${{ matrix.rust }}-
          ${{ matrix.cache-key }}-
    
    - name: Install benchmark tools
      run: |
        if [ "${{ matrix.rust }}" = "nightly" ]; then
          cargo install cargo-criterion --locked || true
        fi
        cargo install criterion --features=html_reports --locked || true
    
    - name: Run benchmarks
      run: |
        cd benchmarks
        if [ "${{ matrix.rust }}" = "nightly" ]; then
          cargo bench --no-fail-fast --features=unstable -- --warm-up-time 1 --measurement-time 3 --sample-size 10 --output-format=json | tee benchmark-results.json
        else
          cargo bench --no-fail-fast -- --output-format=json | tee benchmark-results.json
        fi
    
    - name: Upload benchmark results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ matrix.os }}-${{ matrix.rust }}
        path: benchmarks/benchmark-results.json
        if-no-files-found: warn
        retention-days: 1

  benchmark-history:
    name: Track Benchmark History
    needs: benchmark
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results
        path: benchmark-results

    - name: Process benchmark results
      run: |
        # Create benchmark data directory
        mkdir -p benchmark-data
        
        # Process each benchmark result file
        for file in benchmark-results/*.json; do
          if [ -f "$file" ]; then
            # Extract benchmark name from filename
            name=$(basename "$file" .json)
            
            # Create a simple markdown report
            echo "# Benchmark Results for $name" > "benchmark-data/$name.md"
            echo -e "\n## Raw Data" >> "benchmark-data/$name.md"
            echo '```json' >> "benchmark-data/$name.md"
            cat "$file" >> "benchmark-data/$name.md"
            echo '```' >> "benchmark-data/$name.md"
            
            echo "Processed $file"
          fi
        done
        
        # Generate a summary report
        echo "# Benchmark Results Summary" > "benchmark-data/summary.md"
        echo "## $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> "benchmark-data/summary.md"
        echo "" >> "benchmark-data/summary.md"
        
        # Add a table of contents
        echo "## Table of Contents" >> "benchmark-data/summary.md"
        for file in benchmark-results/*.json; do
          if [ -f "$file" ]; then
            name=$(basename "$file" .json)
            echo "- [$name](#$(echo $name | tr '[:upper:]' '[:lower:]' | tr ' ' '-'))" >> "benchmark-data/summary.md"
          fi
        done
        
        echo "Benchmark results processed"
    
    - name: Upload processed results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-reports
        path: benchmark-data/
        retention-days: 907
    
    - name: Create GitHub Release with results
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      uses: softprops/action-gh-release@v2
      with:
        files: |
          benchmark-results/*.json
          summary.md
        body_path: summary.md
        generate_release_notes: true
        prerelease: false
    
    - name: Update benchmark history
      run: |
        # Create a directory for benchmark history
        mkdir -p benchmark-history
        
        # Process each result file
        for file in benchmark-results/*.json; do
          if [ -f "$file" ]; then
            # Generate a filename with timestamp
            timestamp=$(date -u +"%Y%m%dT%H%M%SZ")
            base_name=$(basename "${file%.*}")
            cp "$file" "benchmark-history/${base_name}_${timestamp}.json"
            
            # Update the index
            echo "- [${base_name} ${timestamp}](${base_name}_${timestamp}.json)" >> benchmark-history/index.md
          fi
        done
        
        # Sort the index file for better readability
        if [ -f "benchmark-history/index.md" ]; then
          sort -r benchmark-history/index.md -o benchmark-history/index.md
        fi
        
        # Configure git and commit changes
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Only commit if there are changes
        git add benchmark-history/
        git diff --quiet && git diff --staged --quiet || \
          (git commit -m "Update benchmark history [skip ci]" && git push)

  # The dashboard generation has been moved to a separate workflow file:
  # .github/workflows/benchmark-dashboard.yml
  # This allows for better separation of concerns and more efficient workflow execution.
  # The dashboard will be generated and deployed automatically after the benchmarks complete.
